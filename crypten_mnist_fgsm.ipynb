{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "v0JTZWCDLygu"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReemAlsharabi/CryptoRobustTraining/blob/main/crypten_mnist_fgsm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### deps"
      ],
      "metadata": {
        "id": "G_QrXyneBG8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't pip install crypten directly because you'll get [this error](https://github.com/facebookresearch/CrypTen/issues/466)"
      ],
      "metadata": {
        "id": "zqn6VWdF5Mqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch>=1.7.0 torchvision>=0.9.1 omegaconf>=2.0.6 onnx>=1.7.0 pandas>=1.2.2 pyyaml>=5.3.1 tensorboard future scipy>=1.6.0 wget"
      ],
      "metadata": {
        "id": "Mug_Fml109ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-deps crypten"
      ],
      "metadata": {
        "id": "1UdsipiNldyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563ddc02-2e9c-4169-9140-e31172f63303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crypten\n",
            "  Downloading crypten-0.4.1-py3-none-any.whl (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.9/259.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: crypten\n",
            "Successfully installed crypten-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import crypten\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import wget\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "crypten.init()\n",
        "torch.set_num_threads(1)"
      ],
      "metadata": {
        "id": "6upGs0Wk8RpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    # random.seed(seed)\n",
        "    # np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "2rao7_r8a9Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "lz6sloSJVhO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data"
      ],
      "metadata": {
        "id": "W4DFbv_FetTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = torchvision.datasets.MNIST(root='/tmp/data',\n",
        "                                           train=True,\n",
        "                                           transform=torchvision.transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "data_test = torchvision.datasets.MNIST(root='/tmp/data',\n",
        "                                           train=False,\n",
        "                                           transform=torchvision.transforms.ToTensor(),\n",
        "                                           download=True)"
      ],
      "metadata": {
        "id": "fqKCsUU9BaSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "befc60d3-186a-43d0-ec14-6576a9e1b22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 127947705.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 132099993.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 36942680.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5681636.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def take_samples(data, n_samples=1000):\n",
        "    \"\"\"Returns images and labels based on sample size\"\"\"\n",
        "    images, labels = [], []\n",
        "\n",
        "    for i, d in enumerate(data):\n",
        "        if i == n_samples:\n",
        "            break\n",
        "        image, label = d\n",
        "        images.append(image)\n",
        "        label_one_hot = torch.nn.functional.one_hot(torch.tensor(label), 10)\n",
        "        labels.append(label_one_hot)\n",
        "\n",
        "    images = torch.cat(images)\n",
        "    labels = torch.stack(labels)\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "zdYM71RkByaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_train, labels_train = take_samples(data_train, n_samples=100)\n",
        "print(images_train.shape)\n",
        "print(labels_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNRjpF1lB7ws",
        "outputId": "44a1d0fd-7f27-4b35-9631-bea86029375c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 28, 28])\n",
            "torch.Size([100, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_train_enc = crypten.cryptensor(images_train, requires_grad=True)\n",
        "labels_train_enc = crypten.cryptensor(labels_train, requires_grad=True)\n",
        "\n",
        "# test set\n",
        "images_test, labels_test = take_samples(data_test, n_samples=20)\n",
        "images_test_enc = crypten.cryptensor(images_test, requires_grad=True)\n",
        "labels_test_enc = crypten.cryptensor(labels_test, requires_grad=True)"
      ],
      "metadata": {
        "id": "6Xe876LWCAQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_train_enc[0]"
      ],
      "metadata": {
        "id": "2wJc-Q4yCDxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7310f4b1-d574-4136-f3a0-817872b11a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MPCTensor(\n",
              "\t_tensor=tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,   771,  4626,  4626,  4626, 32382, 34952, 44975,  6682,\n",
              "         42662, 65536, 63479, 32639,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,  7710,  9252,\n",
              "         24158, 39578, 43690, 65021, 65021, 65021, 65021, 65021, 57825, 44204,\n",
              "         65021, 62194, 50115, 16448,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0, 12593, 61166, 65021,\n",
              "         65021, 65021, 65021, 65021, 65021, 65021, 65021, 64507, 23901, 21074,\n",
              "         21074, 14392, 10023,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,  4626, 56283, 65021,\n",
              "         65021, 65021, 65021, 65021, 50886, 46774, 63479, 61937,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0, 20560, 40092,\n",
              "         27499, 65021, 65021, 52685,  2827,     0, 11051, 39578,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,  3598,\n",
              "           257, 39578, 65021, 23130,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0, 35723, 65021, 48830,   514,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,  2827, 48830, 65021, 17990,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,  8995, 61937, 57825, 41120, 27756,   257,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0, 20817, 61680, 65021, 65021, 30583,  6425,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0, 11565, 47802, 65021, 65021, 38550,  6939,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,  4112, 23901, 64764, 65021, 48059,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0, 63993, 65021, 63993,\n",
              "         16448,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0, 11822, 33410, 47031, 65021, 65021, 53199,\n",
              "           514,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0, 10023, 38036, 58853, 65021, 65021, 65021, 64250, 46774,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "          6168, 29298, 56797, 65021, 65021, 65021, 65021, 51657, 20046,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,  5911, 16962,\n",
              "         54741, 65021, 65021, 65021, 65021, 50886, 20817,   514,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,  4626, 43947, 56283, 65021,\n",
              "         65021, 65021, 65021, 50115, 20560,  2313,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0, 14135, 44204, 58082, 65021, 65021, 65021,\n",
              "         65021, 62708, 34181,  2827,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0, 34952, 65021, 65021, 65021, 54484, 34695,\n",
              "         33924,  4112,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0]])\n",
              "\tplain_text=HIDDEN\n",
              "\tptype=ptype.arithmetic\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encrypted model"
      ],
      "metadata": {
        "id": "spBwA-wVebkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Enc(crypten.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = crypten.nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = crypten.nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = crypten.nn.Dropout2d(0.25)\n",
        "        self.dropout2 = crypten.nn.Dropout2d(0.5)\n",
        "        self.fc1 = crypten.nn.Linear(64*12*12, 128)\n",
        "        self.fc2 = crypten.nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.conv1(x)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x)\n",
        "        x = x.relu()\n",
        "        x = x.max_pool2d(2)\n",
        "        x = self.dropout1(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = x.relu()\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vLX1YytXCq75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has to be encrypted so we train it on CrypTensors. [See why](https://github.com/facebookresearch/CrypTen/issues/279)"
      ],
      "metadata": {
        "id": "8pYFpO97D1Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN_Enc().encrypt()"
      ],
      "metadata": {
        "id": "YUDmSFwZCkL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = images_train_enc[0].unsqueeze(0)\n",
        "print(x.shape)\n",
        "model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28UfPd52Dohd",
        "outputId": "1f8face9-a7b4-41e1-95bf-c6b91c8bff5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MPCTensor(\n",
              "\t_tensor=tensor([[ 9263, -5638, -3432,  2022,  -209,  5508,  3322, -4478, -6147,  2496]])\n",
              "\tplain_text=HIDDEN\n",
              "\tptype=ptype.arithmetic\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### encrypted training"
      ],
      "metadata": {
        "id": "j6sXnFb2BnN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How does CrypTen training differ from PyTorch training?**\n",
        "\n",
        "There are two main ways implementing a CrypTen training loop differs from a PyTorch training loop. We'll describe these items first, and then illustrate them with small examples below.\n",
        "\n",
        "(1) Use one-hot encoding: CrypTen training requires all labels to use one-hot encoding. This means that when using standard datasets such as MNIST, we need to modify the labels to use one-hot encoding.\n",
        "\n",
        "(2) Directly update parameters: CrypTen does not use the PyTorch optimizers. Instead, CrypTen implements encrypted SGD by implementing its own backward function, followed by directly updating the parameters, using SGD in CrypTen is very similar to using the PyTorch optimizers. [Implementing other optmizers](https://github.com/facebookresearch/CrypTen/issues/405) is also possible.\n",
        "\n",
        "[source](https://github.com/facebookresearch/CrypTen/blob/f4cbdfc685d9064f45a5654dee9f3809f6d93e7f/tutorials/Tutorial_7_Training_an_Encrypted_Neural_Network.ipynb)"
      ],
      "metadata": {
        "id": "t6bqVPa6Z0NQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, X, y, epochs=10, learning_rate=0.05):\n",
        "    criterion = crypten.nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        model.zero_grad()\n",
        "        output = model(X)\n",
        "        loss = criterion(output, y)\n",
        "        print(f\"epoch {epoch} loss: {loss.get_plain_text()}\")\n",
        "        loss.backward()\n",
        "        grads = X.grad\n",
        "        # print(grads)\n",
        "        model.update_parameters(learning_rate)\n",
        "    return model, grads\n",
        "\n",
        "# for inference use with crypten.no_grad():"
      ],
      "metadata": {
        "id": "CZTqv85JCj90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, grads = train_model(model, images_train_enc, labels_train_enc, epochs=5, learning_rate=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1vLIagKuxQg",
        "outputId": "4d44c04c-f833-41f2-de28-573146f6db3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 loss: 2.3063507080078125\n",
            "epoch 1 loss: 2.3021240234375\n",
            "epoch 2 loss: 2.3012542724609375\n",
            "epoch 3 loss: 2.2913665771484375\n",
            "epoch 4 loss: 2.28167724609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model(images_test_enc[3].unsqueeze(0)).argmax()\n",
        "prediction.get_plain_text()\n"
      ],
      "metadata": {
        "id": "zhN3sf8rE1EW",
        "outputId": "d91b567a-3c46-4317-b150-dcf30f77c9cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_test[3] # ground truth"
      ],
      "metadata": {
        "id": "lbtCUdwBE-QJ",
        "outputId": "1fd32e24-4d4e-40ce-d83d-7e2eeec50252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fgsm"
      ],
      "metadata": {
        "id": "GDrjrcqeR8K2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(input, epsilon, data_grad):\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    perturbed_input = input + epsilon * sign_data_grad\n",
        "    return perturbed_input"
      ],
      "metadata": {
        "id": "80aa2fw0noMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perturbed_images = []\n",
        "for i in range(len(images_test_enc)):\n",
        "    input = images_test_enc[i]\n",
        "    grad = grads[i]\n",
        "    perturbed_input = fgsm_attack(input, 0.05, grad)\n",
        "    perturbed_images.append(perturbed_input)"
      ],
      "metadata": {
        "id": "fAmcm3XH2srS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_prediction = model(perturbed_images[3].unsqueeze(0)).argmax()\n",
        "adv_prediction.get_plain_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29PZIHnS2veh",
        "outputId": "4d3ce980-5cb6-4732-c370-4029663fd1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### auto-attack"
      ],
      "metadata": {
        "id": "v0JTZWCDLygu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "not compatible with crypten tensors. Override AutoAttack class or re-implement the attacks?\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0fo69YXVrqWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/fra31/auto-attack"
      ],
      "metadata": {
        "id": "moZo1qckGL5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autoattack import AutoAttack"
      ],
      "metadata": {
        "id": "fRBQkDM5L3Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(input):\n",
        "    logits = model(input)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "xvgmwuGDQF63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 0.01\n",
        "adversary = AutoAttack(forward_pass(images_test_enc), norm='Linf', eps=epsilon, version='standard')"
      ],
      "metadata": {
        "id": "bPxmQ8--ZatY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_adv = adversary.run_standard_evaluation(images_test_enc, labels_test_enc, bs=32)"
      ],
      "metadata": {
        "id": "y7sKL6I8ZiNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_adv = adversary.run_standard_evaluation_individual(images_test_enc, labels_test_enc, bs=32)"
      ],
      "metadata": {
        "id": "g2RbKgimfS3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encrypting a Pre-trained Model\n",
        "model pre-trained on plain data (encryption at test-time)"
      ],
      "metadata": {
        "id": "F_PxWMO-HWhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even if we have a pre-trained model, CrypTen will require this structure as input."
      ],
      "metadata": {
        "id": "Sbcj7OvTQLdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model"
      ],
      "metadata": {
        "id": "98dLEPa4SzG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AliceNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AliceNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "crypten.common.serial.register_safe_class(AliceNet)"
      ],
      "metadata": {
        "id": "uaoVveEKDnCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_model = AliceNet() # provide a dummy model to tell CrypTen the model's structure\n",
        "plaintext_model = torch.load('AliceNet.pth')\n",
        "print(plaintext_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDP8QNATEVav",
        "outputId": "5b359860-0af0-4ed5-ccb4-f7cd9de19e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AliceNet(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input = torch.empty((1, 784))\n",
        "private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input) # set up a CrypTen network from the PyTorch network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X22RFAAvEo2y",
        "outputId": "220bac23-d721-4e26-c712-8152132a8dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/crypten/nn/onnx_converter.py:176: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  param = torch.from_numpy(numpy_helper.to_array(node))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "private_model.encrypt()\n",
        "print(\"Model successfully encrypted:\", private_model.encrypted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ak5QtnnEtz3",
        "outputId": "f954eb89-fc52-4557-86e3-977749e7a20e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully encrypted: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluation"
      ],
      "metadata": {
        "id": "x9vriR0xSlb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def take_samples_eval(data, n_samples=1000):\n",
        "    \"\"\"Returns images and labels based on sample size\"\"\"\n",
        "    images, labels = [], []\n",
        "\n",
        "    for i, d in enumerate(data):\n",
        "        if i == n_samples:\n",
        "            break\n",
        "        image, label = d\n",
        "        image = image.view(1, -1) # torch.Size([1, 784])\n",
        "        images.append(image)\n",
        "        label_one_hot = torch.nn.functional.one_hot(torch.tensor(label), 10)\n",
        "        labels.append(label_one_hot)\n",
        "\n",
        "    images = torch.cat(images)\n",
        "    labels = torch.stack(labels)\n",
        "    return images, labels\n",
        "# test set\n",
        "images_test_eval, labels_test_eval = take_samples_eval(data_test, n_samples=20)\n",
        "images_test_enc_eval = crypten.cryptensor(images_test_eval, requires_grad=True)\n",
        "labels_test_enc_eval = crypten.cryptensor(labels_test_eval, requires_grad=True)"
      ],
      "metadata": {
        "id": "hx5M_YR-sk9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_plain_model(model, X, y):\n",
        "    correct_count = 0\n",
        "    criterion = crypten.nn.CrossEntropyLoss()\n",
        "\n",
        "    model.eval()\n",
        "    for i in range(len(X)):\n",
        "      input_data = X[i]\n",
        "      output = model(input_data)\n",
        "\n",
        "      loss = criterion(output, y[i])\n",
        "      loss.backward()\n",
        "\n",
        "      grads = X.grad\n",
        "      # print(grads)\n",
        "      correct = (output[0].argmax().get_plain_text()).eq(y[i].get_plain_text())\n",
        "      correct_count += correct.sum(0, keepdim=True).float()\n",
        "\n",
        "    print(\"Accuracy: \", (correct_count.item() / len(y))*100)\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "rmtR5-nrS9xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grads_pl = test_plain_model(private_model, images_test_enc_eval, labels_test_enc_eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jbclnCNTBT-",
        "outputId": "d48d971b-b1a2-4662-dd95-f50bd94d857e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fgsm"
      ],
      "metadata": {
        "id": "kr_8aB-TeScc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perturbed_images_eval = []\n",
        "for i in range(len(images_test_enc_eval)):\n",
        "    input = images_test_enc_eval[i]\n",
        "    grad = grads_pl[i]\n",
        "    perturbed_input = fgsm_attack(input, 0.01, grad)\n",
        "    perturbed_images_eval.append(perturbed_input)"
      ],
      "metadata": {
        "id": "Abj5LnR5gzHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_prediction = private_model(perturbed_images_eval[2].unsqueeze(0)).argmax()\n",
        "adv_prediction.get_plain_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPXWDpR-h1IW",
        "outputId": "c0ac2fab-3025-4506-e747-3213572e69be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XFXJt-5gyeVg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}